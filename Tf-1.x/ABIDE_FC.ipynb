{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faaef448",
   "metadata": {},
   "source": [
    "Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c3d0f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/celery/.pyenv/versions/GAT/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/home/celery/.pyenv/versions/GAT/lib/python3.5/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/celery/.pyenv/versions/GAT/lib/python3.5/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.datasets.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os #give access to OS functionality, like working with files and folder\n",
    "import csv #Allows reading and writing CSV files\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import sklearn\n",
    "from sklearn.covariance import GraphicalLassoCV\n",
    "import nilearn\n",
    "from nilearn import connectome\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1f51ec",
   "metadata": {},
   "source": [
    "Manage Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1826862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output path\n",
    "save_path = '/home/celery/Documents/Research/dataset/Outputs'\n",
    "\n",
    "# Number of subjects\n",
    "num_subjects = 1000\n",
    "\n",
    "# Selected pipeline\n",
    "pipeline = 'cpac'\n",
    "\n",
    "# Files to fetch\n",
    "derivatives = ['rois_ho']\n",
    "\n",
    "# Get the root folder\n",
    "root_folder = '/home/celery/Documents/Research/dataset/Outputs/cpac/filt_global/rois_ho'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b9fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(num_subjects=None, short=True):\n",
    "    \"\"\"\n",
    "        num_subjects   : number of subject IDs to get\n",
    "        short          : True of False, specifies whether to get short or long subject IDs (Eg: 51431 or NYU_0051431_session_1_rest_1)\n",
    "\n",
    "    return:\n",
    "        subject_IDs    : list of subject IDs (length num_subjects)\n",
    "    \"\"\"\n",
    "\n",
    "    if short:\n",
    "        subject_IDs = np.loadtxt('/home/celery/Documents/Research/dataset/valid_subject_ids.txt', dtype=int)\n",
    "        subject_IDs = subject_IDs.astype(str)\n",
    "    else:\n",
    "        subject_IDs = np.loadtxt('/home/celery/Documents/Research/dataset/full_subject_ids.txt', dtype=str)\n",
    "\n",
    "    if num_subjects is not None:\n",
    "        subject_IDs = subject_IDs[:num_subjects]\n",
    "\n",
    "    return subject_IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce8af60",
   "metadata": {},
   "source": [
    "Testing after getting ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d8ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subject_IDs = get_ids(num_subjects=None, short=True)\n",
    "print(\"Subject IDs:\", subject_IDs)\n",
    "print(\"Number of IDs:\", len(subject_IDs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb2a900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_filenames(subject_list, file_type):\n",
    "    \"\"\"\n",
    "        subject_list : list of short subject IDs in string format\n",
    "        file_type    : must be one of the available file types\n",
    "\n",
    "    returns:\n",
    "\n",
    "        filenames    : list of filetypes (same length as subject_list)\n",
    "    \"\"\"\n",
    "\n",
    "    # Specify file mappings for the possible file types\n",
    "    filemapping = {'func_preproc': '_func_preproc.nii.gz',\n",
    "                   'rois_aal': '_rois_aal.1D',\n",
    "                   'rois_cc200': '_rois_cc200.1D',\n",
    "                   'rois_ho': '_rois_ho.1D'}\n",
    "\n",
    "    # The list to be filled\n",
    "    filenames = []\n",
    "\n",
    "    # Load subject ID lists\n",
    "    subject_IDs = get_ids(short=True)\n",
    "    subject_IDs = subject_IDs.tolist()\n",
    "    full_IDs = get_ids(short=False)\n",
    "\n",
    "    # Fill list with requested file paths\n",
    "    for s in subject_list:\n",
    "        try:\n",
    "            if file_type in filemapping:\n",
    "                idx = subject_IDs.index(s)\n",
    "                pattern = full_IDs[idx] + filemapping[file_type]\n",
    "            else:\n",
    "                pattern = s + file_type\n",
    "\n",
    "\n",
    "            filenames.append(os.path.join(root_folder, pattern))\n",
    "        except ValueError:\n",
    "            # Return N/A if subject ID is not found\n",
    "            filenames.append('N/A')\n",
    "\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f64e813",
   "metadata": {},
   "source": [
    "Testing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac452d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_subjects = ['50724', '51585']\n",
    "file_type = 'rois_ho'\n",
    "\n",
    "file_list = fetch_filenames(test_subjects, file_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bff8828c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/celery/Documents/Research/dataset/Outputs/cpac/filt_global/rois_ho/Leuven_2_0050724_rois_ho.1D\n",
      "/home/celery/Documents/Research/dataset/Outputs/cpac/filt_global/rois_ho/SBL_0051585_rois_ho.1D\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for f in file_list:\n",
    "    print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6a3a3944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_subject_file(subject_id, folder_path, suffix='_rois_ho.1D'):\n",
    "    \"\"\"\n",
    "    Search for a file in folder_path that matches the given subject_id.\n",
    "\n",
    "    subject_id   : short subject ID like '50004'\n",
    "    folder_path  : the path where .1D files are stored (e.g., rois_ho folder)\n",
    "    suffix       : file suffix to look for (default is '_rois_ho.1D')\n",
    "\n",
    "    Returns:\n",
    "        file_path  : full path to the matching file, or 'N/A' if not found\n",
    "    \"\"\"\n",
    "    for fname in os.listdir(folder_path):\n",
    "        if subject_id in fname and fname.endswith(suffix):\n",
    "            return os.path.join(folder_path, fname)\n",
    "    return 'N/A'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb6f223",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1d03ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 50004 -> /home/celery/Documents/Research/dataset/Outputs/cpac/filt_global/rois_ho/Pitt_0050004_rois_ho.1D\n",
      "Subject 50005 -> /home/celery/Documents/Research/dataset/Outputs/cpac/filt_global/rois_ho/Pitt_0050005_rois_ho.1D\n",
      "Subject 50006 -> /home/celery/Documents/Research/dataset/Outputs/cpac/filt_global/rois_ho/Pitt_0050006_rois_ho.1D\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/celery/Documents/Research/dataset/Outputs/cpac/filt_global/rois_ho/\" # this function is different from the  code because my data is flattened\n",
    "subject_ids = ['50004', '50005', '50006']\n",
    "\n",
    "for sid in subject_ids:\n",
    "    file_path = find_subject_file(sid, folder_path)\n",
    "    print(\"Subject\", sid, \"->\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78b532c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def fetch_conn_matrices(subject_list, atlas_name, kind): #fetch mat file after subject_connectivity()\\n    \"\"\"\\n        subject_list : list of short subject IDs in string format\\n        atlas_name   : the atlas based on which the timeseries are generated e.g. aal, cc200\\n        kind         : the kind of correlation used to estimate the matrices, i.e.\\n\\n    returns:\\n        connectivity : list of square connectivity matrices, one for each subject in subject_list\\n    \"\"\"\\n\\n    conn_files = fetch_filenames(subject_list,\\n                                 \\'_\\' + atlas_name + \\'_\\' + kind.replace(\\' \\', \\'_\\') + \\'.mat\\')\\n\\n    conn_matrices = []\\n\\n    for fl in conn_files:\\n        print(\"Reading connectivity file %s\" % fl)\\n        try:\\n            mat = sio.loadmat(fl)[\\'connectivity\\']\\n            conn_matrices.append(mat)\\n        except IOError:\\n            print(\"File %s does not exist\" % fl)\\n\\n    return conn_matrices\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def fetch_conn_matrices(subject_list, atlas_name, kind): #fetch mat file after subject_connectivity()\n",
    "    \"\"\"\n",
    "        subject_list : list of short subject IDs in string format\n",
    "        atlas_name   : the atlas based on which the timeseries are generated e.g. aal, cc200\n",
    "        kind         : the kind of correlation used to estimate the matrices, i.e.\n",
    "\n",
    "    returns:\n",
    "        connectivity : list of square connectivity matrices, one for each subject in subject_list\n",
    "    \"\"\"\n",
    "\n",
    "    conn_files = fetch_filenames(subject_list,\n",
    "                                 '_' + atlas_name + '_' + kind.replace(' ', '_') + '.mat')\n",
    "\n",
    "    conn_matrices = []\n",
    "\n",
    "    for fl in conn_files:\n",
    "        print(\"Reading connectivity file %s\" % fl)\n",
    "        try:\n",
    "            mat = sio.loadmat(fl)['connectivity']\n",
    "            conn_matrices.append(mat)\n",
    "        except IOError:\n",
    "            print(\"File %s does not exist\" % fl)\n",
    "\n",
    "    return conn_matrices\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad61465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeseries(subject_list, atlas_name):\n",
    "    \"\"\"\n",
    "        subject_list : list of short subject IDs in string format\n",
    "        atlas_name   : the atlas based on which the timeseries are generated e.g. aal, cc200\n",
    "\n",
    "    returns:\n",
    "        ts           : list of timeseries arrays, each of shape (timepoints x regions)\n",
    "    \"\"\"\n",
    "\n",
    "    ts_files = fetch_filenames(subject_list, 'rois_' + atlas_name)\n",
    "\n",
    "    ts = []\n",
    "\n",
    "    for fl in ts_files:\n",
    "        print(\"Reading timeseries file %s\" % fl)\n",
    "        ts.append(np.loadtxt(fl, skiprows=0))\n",
    "\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67f6ea9",
   "metadata": {},
   "source": [
    "Function testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dffc237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts = get_timeseries(['50004'], 'ho')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2f80e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_timeseries(ts_list):\n",
    "    \"\"\"\n",
    "        ts_list    : list of timeseries arrays, each of shape (timepoints x regions)\n",
    "\n",
    "    returns:\n",
    "        norm_ts    : list of normalised timeseries arrays, same shape as ts_list\n",
    "    \"\"\"\n",
    "\n",
    "    norm_ts = []\n",
    "\n",
    "    for ts in ts_list:\n",
    "        norm_ts.append(nilearn.signal.clean(ts, detrend=False))\n",
    "\n",
    "    return norm_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe77c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_connectivity(timeseries, subject, atlas_name, kind, save=True, save_path=root_folder):\n",
    "    \"\"\"\n",
    "        timeseries   : timeseries table for subject (timepoints x regions)\n",
    "        subject      : the subject short ID\n",
    "        atlas_name   : name of the atlas used\n",
    "        kind         : the kind of connectivity to be used, e.g. lasso, partial correlation, correlation\n",
    "        save         : save the connectivity matrix to a file\n",
    "        save_path    : specify path to save the matrix if different from subject folder\n",
    "\n",
    "    returns:\n",
    "        connectivity : connectivity matrix (regions x regions)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Estimating %s matrix for subject %s\" % (kind, subject))\n",
    "\n",
    "    if kind == 'lasso':\n",
    "        # Graph Lasso estimator\n",
    "        covariance_estimator = GraphicalLassoCV(verbose=1)\n",
    "        covariance_estimator.fit(timeseries)\n",
    "        connectivity = covariance_estimator.covariance_\n",
    "        print('Covariance matrix has shape {0}.'.format(connectivity.shape))\n",
    "\n",
    "    elif kind in ['tangent', 'partial correlation', 'correlation']:\n",
    "        conn_measure = connectome.ConnectivityMeasure(kind=kind)\n",
    "        connectivity = conn_measure.fit_transform([timeseries])[0]\n",
    "\n",
    "    # defining custom save path\n",
    "    save_path_mat = '/home/celery/Documents/Research/dataset/Outputs/cpac/filt_global/mat/'\n",
    "\n",
    "    if save:\n",
    "        subject_file = os.path.join(save_path_mat,\n",
    "                            subject + '_' + atlas_name + '_' + kind.replace(' ', '_') + '.mat')\n",
    "\n",
    "        sio.savemat(subject_file, {'connectivity': connectivity})\n",
    "\n",
    "    return connectivity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a167ff",
   "metadata": {},
   "source": [
    "Function testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d1f52a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts = np.loadtxt('/home/celery/Documents/Research/dataset/Outputs/cpac/filt_global/rois_ho/Caltech_0051473_rois_ho.1D')  # (timepoints x regions)\n",
    "# conn = subject_connectivity(ts, '51473', 'ho', 'correlation') #uncomment to test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "358a7bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat_data = sio.loadmat('/home/celery/Documents/Research/dataset/Outputs/cpac/filt_global/mat/51473_ho_correlation.mat')\n",
    "# print(mat_data.keys())\n",
    "# print(mat_data['connectivity'])\n",
    "# conn = mat_data['connectivity']\n",
    "# print(conn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2f967389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_connectivity(timeseries, subject_list, atlas_name, kind, save=True, save_path=root_folder): #batch version of the function above\n",
    "    \"\"\"\n",
    "        timeseries   : list of timeseries tables for subjects (timepoints x regions)\n",
    "        subject_list : the subject short IDs list\n",
    "        atlas_name   : name of the atlas used\n",
    "        kind         : the kind of connectivity to be used, e.g. lasso, partial correlation, correlation\n",
    "        save         : save the connectivity matrix to a file\n",
    "        save_path    : specify path to save the matrix if different from subject folder\n",
    "\n",
    "    returns:\n",
    "        connectivity : connectivity matrix (regions x regions)\n",
    "    \"\"\"\n",
    "\n",
    "    if kind == 'lasso':\n",
    "        # Graph Lasso estimator\n",
    "        covariance_estimator = GraphicalLassoCV(verbose=1)\n",
    "        connectivity_matrices = []\n",
    "\n",
    "        for i, ts in enumerate(timeseries):\n",
    "            covariance_estimator.fit(ts)\n",
    "            connectivity = covariance_estimator.covariance_\n",
    "            connectivity_matrices.append(connectivity)\n",
    "            print('Covariance matrix has shape {0}.'.format(connectivity.shape))\n",
    "\n",
    "    elif kind in ['tangent', 'partial correlation', 'correlation']:\n",
    "        conn_measure = connectome.ConnectivityMeasure(kind=kind)\n",
    "        connectivity_matrices = conn_measure.fit_transform(timeseries)\n",
    "    # defining custom save path for .mat files\n",
    "    save_path_mat = '/home/celery/Documents/Research/dataset/Outputs/cpac/filt_global/mat/'\n",
    "\n",
    "    if save:\n",
    "        for i, subject in enumerate(subject_list):\n",
    "            subject_file = os.path.join(save_path_mat,\n",
    "                                        subject + '_' + atlas_name + '_' + kind.replace(' ', '_') + '.mat')\n",
    "            sio.savemat(subject_file, {'connectivity': connectivity_matrices[i]})\n",
    "            print(\"Saving connectivity matrix to %s\" % subject_file)\n",
    "\n",
    "    return connectivity_matrices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f30e06",
   "metadata": {},
   "source": [
    "Getting the connectivity from using group function above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9626728",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_file = '/home/celery/Documents/Research/dataset/valid_subject_ids.txt'\n",
    "subject_list = np.loadtxt(subject_file, dtype = str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc63a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_list = get_timeseries(subject_list, 'ho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a39c901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_ts_list = norm_timeseries(ts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4268bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_connectivity(\n",
    "    timeseries=ts_list,\n",
    "    subject_list=subject_list,\n",
    "    atlas_name='ho',\n",
    "    kind='correlation',\n",
    "    save=True,\n",
    "    save_path= '/home/celery/Documents/Research/dataset/Outputs/cpac/filt_global/mat'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
