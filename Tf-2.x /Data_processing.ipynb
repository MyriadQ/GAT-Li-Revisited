{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce8a0ff",
   "metadata": {},
   "source": [
    "1. Process Label files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66871403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "label = pd.read_csv('/Users/celery/Research/dataset/ABCD/abcd_labels.csv')\n",
    "\n",
    "#remove DNAR_ prefix\n",
    "label['src_subject_id'] = label['src_subject_id'].str.replace('_', '', regex = False)\n",
    "#remove anything but the baseline prefix in the eventname column\n",
    "label = label[label['eventname'].str.startswith('baseline')]\n",
    "#saving\n",
    "label.to_csv('/Users/celery/Research/dataset/ABCD/abcd_labels_cleaned.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f6cf71",
   "metadata": {},
   "source": [
    "2. Parse the FC mat file into 4199 68x68 .mat file for each IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d87ac5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 4199 files to /Users/celery/Research/dataset/ABCD/indv_matfile\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import os\n",
    "\n",
    "def _arr_to_string(arr):\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.size == 0:\n",
    "        return ''\n",
    "    if arr.dtype.kind in ('u', 'i'):\n",
    "        vals = arr.flatten()\n",
    "        vals = vals[vals != 0]\n",
    "        try:\n",
    "            return ''.join(chr(int(v)) for v in vals)\n",
    "        except Exception:\n",
    "            try:\n",
    "                vals16 = arr.astype('uint16').flatten()\n",
    "                vals16 = vals16[vals16 != 0]\n",
    "                return ''.join(chr(int(v)) for v in vals16)\n",
    "            except Exception:\n",
    "                return ''.join(map(str, vals))\n",
    "    if arr.dtype.kind in ('S', 'U'):\n",
    "        parts = []\n",
    "        for e in arr.flatten():\n",
    "            if isinstance(e, bytes):\n",
    "                try:\n",
    "                    parts.append(e.decode('utf-8'))\n",
    "                except Exception:\n",
    "                    parts.append(e.decode('latin1', errors='ignore'))\n",
    "            else:\n",
    "                parts.append(str(e))\n",
    "        return ''.join(parts)\n",
    "    return str(arr)\n",
    "\n",
    "def read_id_ndar_qc(mat_path, id_key='id_ndar_qc'):\n",
    "    ids = []\n",
    "    with h5py.File(mat_path, 'r') as f:\n",
    "        refs_ds = f[id_key]\n",
    "        refs = refs_ds[:]\n",
    "        flat = refs.reshape(-1)\n",
    "        for i, r in enumerate(flat):\n",
    "            if isinstance(r, np.ndarray):\n",
    "                if r.dtype.kind in ('u', 'i', 'S', 'U'):\n",
    "                    ids.append(_arr_to_string(r))\n",
    "                    continue\n",
    "                if r.size == 1:\n",
    "                    r = r.reshape(-1)[0]\n",
    "                else:\n",
    "                    try:\n",
    "                        ids.append(_arr_to_string(r))\n",
    "                        continue\n",
    "                    except Exception:\n",
    "                        r = r.reshape(-1)[0]\n",
    "            try:\n",
    "                if isinstance(r, h5py.Reference) or type(r).__name__ == 'Reference':\n",
    "                    ds = f[r]\n",
    "                    data = ds[:]\n",
    "                    ids.append(_arr_to_string(data))\n",
    "                elif isinstance(r, (bytes, str)):\n",
    "                    name = r.decode('utf-8') if isinstance(r, bytes) else r\n",
    "                    if name in f:\n",
    "                        ids.append(_arr_to_string(f[name][:]))\n",
    "                    else:\n",
    "                        ids.append(name)\n",
    "                else:\n",
    "                    try:\n",
    "                        ids.append(_arr_to_string(np.array(r)))\n",
    "                    except Exception as e:\n",
    "                        print(f'Warning: could not decode element {i} (type={type(r)}).')\n",
    "                        ids.append(None)\n",
    "            except Exception as err:\n",
    "                print(f'Warning: failed to dereference element {i}: {err!r}')\n",
    "                ids.append(None)\n",
    "    return ids\n",
    "\n",
    "# --- match IDs with RSFC and save ---\n",
    "matfile = '/Users/celery/Research/dataset/ABCD/abcd_DK_RSFC.mat'\n",
    "output_dir = '/Users/celery/Research/dataset/ABCD/indv_matfile'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Extract IDs\n",
    "ids = read_id_ndar_qc(matfile)\n",
    "\n",
    "# Read RSFC data\n",
    "with h5py.File(matfile, 'r') as f:\n",
    "    rsfc = f['abcd_RSFC_DK'][:]  # shape (subjects, 68, 68)\n",
    "\n",
    "# Check dimensions match\n",
    "if len(ids) != rsfc.shape[0]:\n",
    "    raise ValueError(f\"Number of IDs ({len(ids)}) does not match RSFC subjects ({rsfc.shape[0]})\")\n",
    "\n",
    "# Save each subject\n",
    "for i, subj_id in enumerate(ids):\n",
    "    if subj_id is None or subj_id.strip() == \"\":\n",
    "        continue  # skip invalid IDs\n",
    "    filename = f\"{subj_id}_dk_correlation.mat\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    sio.savemat(filepath, {\"correlation\": rsfc[i]})\n",
    "\n",
    "print(f\"Saved {len(ids)} files to {output_dir}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAT_Newest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
