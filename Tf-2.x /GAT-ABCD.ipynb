{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7f268d4",
   "metadata": {},
   "source": [
    "Importing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f87e9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/attr_value.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/resource_handle.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_shape.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/types.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/full_type.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/function.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/node_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/op_def.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/graph_debug_info.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/versions.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at xla/tsl/protobuf/coordination_config.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/cost_graph.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/step_stats.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/allocation_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/framework/tensor_description.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/cluster.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/GAT_Newest/lib/python3.13/site-packages/google/protobuf/runtime_version.py:98: UserWarning: Protobuf gencode version 5.28.3 is exactly one major version older than the runtime version 6.31.1 at tensorflow/core/protobuf/debug.proto. Please update the gencode to avoid compatibility violations in the next runtime release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecde1ea",
   "metadata": {},
   "source": [
    "Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35168e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a93489d",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "166effe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy.io as sio\n",
    "import random\n",
    "import ABCD_Parser as Reader\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse as sp\n",
    "import scipy.spatial.distance\n",
    "import pickle as pkl\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from tensorflow.python.ops import array_ops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e04bdb9",
   "metadata": {},
   "source": [
    "Libraries for evaluating result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c475e96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f2073c",
   "metadata": {},
   "source": [
    "Define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e84bb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glorot(shape, name = None):\n",
    "  init_range = np.sqrt(6.0/(shape[0]+shape[1]))\n",
    "  initial = tf.random_uniform(shape, minval = -init_range, maxval = init_range, dtype = tf.float32)\n",
    "  var = tf.Variable(initial, name = name)\n",
    "  return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34bc6c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeros(shape, name = None):\n",
    "  \"\"\"All zeros\"\"\"\n",
    "  initial = tf.zeros(shape, dtype=tf.float32)\n",
    "  return tf.Variable(initial, name = name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bce5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot(x,y, sparese = False):\n",
    "  if sparese:\n",
    "    res = tf.sparese_tensor_dense_matmul(x,y)\n",
    "  else:\n",
    "    res = tf.matmul(x,y)\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "431ad45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, labels):\n",
    "  correct_prediction = tf.equal(tf.round(preds), labels)\n",
    "\n",
    "  accuracy = tf.cast(correct_prediction, tf.float32)\n",
    "  return tf.reduce_mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "869f0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tens(shape, name = None):\n",
    "  initial = tf.constant(10, tf.float32, shape)\n",
    "  return tf.Variable(initial, name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e793791",
   "metadata": {},
   "source": [
    "define flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec81b646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<absl.flags._flagvalues.FlagHolder at 0x158fe9c70>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from absl import flags, app\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "flags.DEFINE_integer('node_num', 68, 'Number of Graph nodes')\n",
    "\n",
    "flags.DEFINE_integer('output_dim', 1, 'Number of output_dim')\n",
    "flags.DEFINE_float('learning_rate', 0.0001, 'Initial learning rate') #0.0005，0.0001，0.00005，0.00001，0.00003\n",
    "flags.DEFINE_integer('batch_num', 10, 'Number of epochs to train') #num of batches\n",
    "flags.DEFINE_integer('epochs', 1000, 'Number of epochs to train') #num of epochs/ iterations through the whole\n",
    "flags.DEFINE_integer('attn_heads', 5, 'Number of attention head')\n",
    "\n",
    "flags.DEFINE_integer('hidden1_gat', 24, 'Number of units in hidden layer 1 of gcn') #F_\n",
    "flags.DEFINE_integer('output_gat', 3, 'Number of units in output layer 1 of gcn') #for later\n",
    "\n",
    "flags.DEFINE_float('dropout', 0, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('in_drop', 0, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('weight_decay', 5e-4, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_integer('early_stopping', 15, 'Tolerance for early stopping (# of epochs).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e55fc8",
   "metadata": {},
   "source": [
    "gat_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5863b903",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gat_layer():\n",
    "  def __init__(self, input_dim,F_, placeholders,attn_heads=1,attn_heads_reduction='concat',\n",
    "                 activation=tf.nn.relu, use_bias=True,name_=''):\n",
    "        self.dropout_rate = placeholders['dropout']\n",
    "        #place holder are like container to be filled later by data\n",
    "        # dropout for attention matrix aij to regularize attention mechanism\n",
    "\t\t    # also dropout for feature after transformed to regularize feature transformation\n",
    "        self.in_drop = placeholders['in_drop']\n",
    "\t\t    #dropout for input feature X to regularize input representation\n",
    "        self.name = 'gat_layer'+name_\n",
    "        self.vars = {}\n",
    "        # dictionary to store learnable parameter like weights\n",
    "        self.act = activation\n",
    "        self.attn_heads = attn_heads  # Number of attention heads (K in the paper)\n",
    "        self.attn_heads_reduction = attn_heads_reduction  #concat / avg\n",
    "        self.bias = use_bias\n",
    "        self.A = placeholders[\"adj\"]\n",
    "        #adj matrix\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "        with tf.variable_scope(self.name+'_vars'):\n",
    "            for i in range(self.attn_heads): #loops thru all attention head (K)\n",
    "                self.vars['weights_'+str(i)] = glorot([input_dim, F_], name='weights_' + str(i))\n",
    "                # init the i-th weights using glorot function\n",
    "\t\t\t\t# the shape of the weight matrix is input_dim x F_ with F_\n",
    "                self.vars[\"attn_self_weights_\"+str(i)] = glorot([F_, 1], name='attn_self_weights_' + str(i))\n",
    "\t\t\t\t# weight for attention mechanism on itself, shape F_ x 1\n",
    "                self.vars[\"attn_neighs_weights_\"+str(i)] = glorot([F_, 1], name='attn_neighs_weights_' + str(i))\n",
    "                # weight for attention mechanism on its neighbor, shape F_ x 1\n",
    "        if self.bias:\n",
    "            self.vars['bias'] = zeros([F_],name='bias')\n",
    "\n",
    "  def __call__(self,inputs):\n",
    "      #foward pass\n",
    "      X = inputs\n",
    "      if self.in_drop != 0.0:\n",
    "          X = tf.nn.dropout(X, 1-self.in_drop)\n",
    "\n",
    "      outputs = []\n",
    "      dense_mask = []\n",
    "\n",
    "      for head in range(self.attn_heads):\n",
    "          kernel = self.vars['weights_'+str(head)]\n",
    "          features = tf.tensordot(X, kernel, axes = 1)\n",
    "          # project hi to get hi'\n",
    "\n",
    "          #compute feature combination\n",
    "          attention_self_kernel = self.vars['attn_self_weights_'+str(head)]\n",
    "          #weight for attention mechanism (itself)\n",
    "          attention_neighs_kernel = self.vars['attn_neighs_kernel_'+str(head)]\n",
    "          #weight for attention mechanism (neighbors)\n",
    "          attn_for_self = tf.tensordot(features, attention_self_kernel, axes = 1)\n",
    "          #this give a scalar\n",
    "          attn_for_neighs = tf.tensordot(features, attention_neighs_kernel, axes = 1)\n",
    "          #this also give a scalar\n",
    "\n",
    "          dense = attn_for_self + tf.transpose(attn_for_neighs, [0,2,1]) # N x N\n",
    "\n",
    "          print(\"plus:\", dense.shape)\n",
    "          #score e_ij\n",
    "\n",
    "          #Add nonlinearty\n",
    "          dense = tf.nn.leaky_relu(dense, alpha = 0.2)\n",
    "\n",
    "          #Mask with adj matrix to ensure only neighbor\n",
    "          zero_vec = -9.e15 * tf.ones_like(dense)\n",
    "          dense = tf.where(self.A > 0, dense, zero_vec)\n",
    "          dense_mask.append(dense)\n",
    "\n",
    "          #Apply softmax to get attention coefficient\n",
    "          dense = tf.nn.softmax(dense) #still NxN\n",
    "          #Apply dropout to randomly ignore some neighbor regularize\n",
    "          dropout_attn = tf.nn.dropout(dense, 1-self.dropout_rate) #1-self.drop = drop probability\n",
    "          #this is the coefficient after dropout\n",
    "          dropout_feat = tf.nn.dropout(features, 1-self.dropout_rate) #prevent overfitting\n",
    "          #this is the coefficient after dropout\n",
    "\n",
    "          #Linear combination with neighbor's features\n",
    "          node_features = tf.matmul(dropout_attn,dropout_feat)\n",
    "\n",
    "          if self.bias:\n",
    "             node_features += self.vars['bias']\n",
    "\n",
    "          #Add output of attention head to final output\n",
    "          if self.attn_heads_reduction == 'concat':\n",
    "              outputs.append(self.act(node_features))\n",
    "          else:\n",
    "              outputs.append(node_features)\n",
    "\n",
    "        #Aggregate the heads's output\\\n",
    "      if self.attn_heads_reduction == 'concat': #concat\n",
    "        output = tf.concat(outputs, axis = -1)\n",
    "      else:\n",
    "          output = tf.add_n(outputs) / self.attn_heads  #average\n",
    "          output = self.act(output)\n",
    "\n",
    "      return output, dense_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9900c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fc_layer():\n",
    "  def __init__(self, input_dim, output_dim, placeholders, dropout = 0., sparse_input = False, act = tf.nn.relu, bias = False,\n",
    "               featureless = False, name_ = ''):\n",
    "    if dropout:\n",
    "      self.dropout = placeholders['dropout']\n",
    "    else:\n",
    "      self.dropout = 0.\n",
    "\n",
    "    self.name = 'fc_layer'+ name_\n",
    "    self.vars = {}\n",
    "    self.act = act\n",
    "\n",
    "    self.sparse_input = sparse_input\n",
    "    self.featureless = featureless\n",
    "    self.bias = bias\n",
    "\n",
    "    with tf.variable_scope(self.name + '_vars'):\n",
    "      self.vars['weights'] = glorot([input_dim, output_dim], name = 'weights')\n",
    "\n",
    "    if self.bias:\n",
    "      self.vars['bias'] = zeros([output_dim], name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71b4a4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAT_Newest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
