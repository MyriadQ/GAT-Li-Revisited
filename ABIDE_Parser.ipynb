{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "136dd9f2",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d38083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/celery/.pyenv/versions/3.5.10/envs/GAT/lib/python3.5/site-packages/nilearn/__init__.py:68: FutureWarning: Python 3.5 support is deprecated and will be removed in a future release. Consider switching to Python 3.6 or 3.7\n",
      "  _python_deprecation_warnings()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from nilearn import connectome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438e2f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype = '/home/celery/Documents/Research/dataset/Phenotypic_V1_0b_preprocessed1.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dff2a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(subject_list):\n",
    "    label_dict = {}\n",
    "    with open(phenotype) as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        for row in reader:\n",
    "            if row['SUB_ID'] in subject_list:\n",
    "                label = int(row['DX_GROUP'])\n",
    "                if label == 2:\n",
    "                    label_dict[row['SUB_ID']] = 0\n",
    "                else:\n",
    "                    label_dict[row['SUB_ID']] = 1\n",
    "\n",
    "    return label_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1189f70c",
   "metadata": {},
   "source": [
    "Function testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2840e76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'50004': 1, '50006': 1, '50005': 1}\n"
     ]
    }
   ],
   "source": [
    "subject_list = ['50004', '50005', '50006']  # Replace with actual short IDs \n",
    "label_dict = get_label(subject_list)\n",
    "print(label_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70858f81",
   "metadata": {},
   "source": [
    "Got all connectivity already by running the code from the repo: https://github.com/sk1712/gcn_metric_learning/blob/master/lib/abide_utils.py\n",
    "\n",
    "The code below assume you already have the .mat file from running the repo above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a748caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_connectivity(subject_list, kind, atlas_name = 'ho'):\n",
    "    \"\"\"\n",
    "\n",
    "        subject_list : the subject short IDs list\n",
    "\n",
    "        kind         : the kind of connectivity to be used, e.g. lasso, partial correlation, correlation\n",
    "\n",
    "        atlas_name   : name of the atlas used\n",
    "    returns:\n",
    "\n",
    "        all_networks : list of connectivity matrices (regions x regions)\n",
    "    \"\"\"\n",
    "    data_folder = '/home/celery/Documents/Research/dataset/Outputs/cpac/filt_global/mat/'\n",
    "    all_networks = []\n",
    "    for subject in subject_list:\n",
    "        fl = os.path.join(data_folder, subject + \"_\" + atlas_name + \"_\" + kind + \".mat\")\n",
    "        matrix = sio.loadmat(fl)['connectivity']\n",
    "        if atlas_name == 'ho':\n",
    "            matrix = np.delete(matrix, 82, axis=0)\n",
    "            matrix = np.delete(matrix, 82, axis=1)\n",
    "        all_networks.append(matrix)\n",
    "    all_networks=np.array(all_networks)\n",
    "    return all_networks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d3beb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getconn_vector(subject_name, kind, atlas, label_dict):\n",
    "    subject_name = np.array(subject_name0)\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    conn_array = load_connectivity(subject_name, kind, atlas)\n",
    "    # Get upper diagonal indices\n",
    "    idx = np.triu_indices_from(conn_array[0], 1)\n",
    "    # Get vectorised matrices\n",
    "    vec_networks = [mat[idx] for mat in conn_array]\n",
    "    # Each subject should be a row of the matrix\n",
    "    data_x = np.array(vec_networks)\n",
    "    \n",
    "    for subname in subject_name:\n",
    "        data_y.append(int(label_dict[subname]))\n",
    "    \n",
    "    data_y = np.array(data_y)\n",
    "    print(\"conn vector generator finished\")\n",
    "    return data_x, data_y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
